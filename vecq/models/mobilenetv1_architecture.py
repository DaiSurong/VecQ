# Architecture reconstruction
import keras
import sys
sys.path.append('../')
from ..quantize_layers import Conv2D_Q, Dense_Q, DepthwiseConv2D_Q
def MobileNetV1(kq=None,
		bq=None,
		aq=None,
		activation=None,
		after_activation=None):
	inputs=keras.layers.Input(shape=(224,224,3))
	x=keras.layers.convolutional.ZeroPadding2D(name='conv1_pad',
		trainable=True,
		padding=((0, 1), (0, 1)),
		data_format='channels_last')(inputs)
	x=Conv2D_Q(name='conv1',
		trainable=True,
		filters=32,
		kernel_size=(3, 3),
		strides=(2, 2),
		padding='valid',
		data_format='channels_last',
		dilation_rate=(1, 1),
		activation=activation,
		use_bias=False,
		kernel_regularizer=None,
		bias_regularizer=None,
		activity_regularizer=None,
		kernel_constraint=None,
		bias_constraint=None,
		kq=kq,
		bq=bq,
		aq=aq,
		after_activation=after_activation)(x)
	x=keras.layers.normalization.BatchNormalization(name='conv1_bn',
		trainable=True,
		axis=-1,
		momentum=0.99,
		epsilon=0.001,
		center=True,
		scale=True,
		beta_initializer={'class_name': 'Zeros', 'config': {}},
		gamma_initializer={'class_name': 'Ones', 'config': {}},
		moving_mean_initializer={'class_name': 'Zeros', 'config': {}},
		moving_variance_initializer={'class_name': 'Ones', 'config': {}},
		beta_regularizer=None,
		gamma_regularizer=None,
		beta_constraint=None,
		gamma_constraint=None)(x)
	x=keras.layers.advanced_activations.ReLU(name='conv1_relu',
		trainable=True,
		max_value=6.0,
		negative_slope=0.0,
		threshold=0.0)(x)
	x=DepthwiseConv2D_Q(name='conv_dw_1',
		trainable=True,
		kernel_size=(3, 3),
		strides=(1, 1),
		padding='same',
		data_format='channels_last',
		dilation_rate=(1, 1),
		activation=activation,
		use_bias=False,
		bias_regularizer=None,
		activity_regularizer=None,
		bias_constraint=None,
		depth_multiplier=1,
		depthwise_initializer={'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}},
		depthwise_regularizer=None,
		depthwise_constraint=None,
		kq=kq,
		bq=bq,
		aq=aq,
		after_activation=after_activation)(x)
	x=keras.layers.normalization.BatchNormalization(name='conv_dw_1_bn',
		trainable=True,
		axis=-1,
		momentum=0.99,
		epsilon=0.001,
		center=True,
		scale=True,
		beta_initializer={'class_name': 'Zeros', 'config': {}},
		gamma_initializer={'class_name': 'Ones', 'config': {}},
		moving_mean_initializer={'class_name': 'Zeros', 'config': {}},
		moving_variance_initializer={'class_name': 'Ones', 'config': {}},
		beta_regularizer=None,
		gamma_regularizer=None,
		beta_constraint=None,
		gamma_constraint=None)(x)
	x=keras.layers.advanced_activations.ReLU(name='conv_dw_1_relu',
		trainable=True,
		max_value=6.0,
		negative_slope=0.0,
		threshold=0.0)(x)
	x=Conv2D_Q(name='conv_pw_1',
		trainable=True,
		filters=64,
		kernel_size=(1, 1),
		strides=(1, 1),
		padding='same',
		data_format='channels_last',
		dilation_rate=(1, 1),
		activation=activation,
		use_bias=False,
		kernel_regularizer=None,
		bias_regularizer=None,
		activity_regularizer=None,
		kernel_constraint=None,
		bias_constraint=None,
		kq=kq,
		bq=bq,
		aq=aq,
		after_activation=after_activation)(x)
	x=keras.layers.normalization.BatchNormalization(name='conv_pw_1_bn',
		trainable=True,
		axis=-1,
		momentum=0.99,
		epsilon=0.001,
		center=True,
		scale=True,
		beta_initializer={'class_name': 'Zeros', 'config': {}},
		gamma_initializer={'class_name': 'Ones', 'config': {}},
		moving_mean_initializer={'class_name': 'Zeros', 'config': {}},
		moving_variance_initializer={'class_name': 'Ones', 'config': {}},
		beta_regularizer=None,
		gamma_regularizer=None,
		beta_constraint=None,
		gamma_constraint=None)(x)
	x=keras.layers.advanced_activations.ReLU(name='conv_pw_1_relu',
		trainable=True,
		max_value=6.0,
		negative_slope=0.0,
		threshold=0.0)(x)
	x=keras.layers.convolutional.ZeroPadding2D(name='conv_pad_2',
		trainable=True,
		padding=((0, 1), (0, 1)),
		data_format='channels_last')(x)
	x=DepthwiseConv2D_Q(name='conv_dw_2',
		trainable=True,
		kernel_size=(3, 3),
		strides=(2, 2),
		padding='valid',
		data_format='channels_last',
		dilation_rate=(1, 1),
		activation=activation,
		use_bias=False,
		bias_regularizer=None,
		activity_regularizer=None,
		bias_constraint=None,
		depth_multiplier=1,
		depthwise_initializer={'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}},
		depthwise_regularizer=None,
		depthwise_constraint=None,
		kq=kq,
		bq=bq,
		aq=aq,
		after_activation=after_activation)(x)
	x=keras.layers.normalization.BatchNormalization(name='conv_dw_2_bn',
		trainable=True,
		axis=-1,
		momentum=0.99,
		epsilon=0.001,
		center=True,
		scale=True,
		beta_initializer={'class_name': 'Zeros', 'config': {}},
		gamma_initializer={'class_name': 'Ones', 'config': {}},
		moving_mean_initializer={'class_name': 'Zeros', 'config': {}},
		moving_variance_initializer={'class_name': 'Ones', 'config': {}},
		beta_regularizer=None,
		gamma_regularizer=None,
		beta_constraint=None,
		gamma_constraint=None)(x)
	x=keras.layers.advanced_activations.ReLU(name='conv_dw_2_relu',
		trainable=True,
		max_value=6.0,
		negative_slope=0.0,
		threshold=0.0)(x)
	x=Conv2D_Q(name='conv_pw_2',
		trainable=True,
		filters=128,
		kernel_size=(1, 1),
		strides=(1, 1),
		padding='same',
		data_format='channels_last',
		dilation_rate=(1, 1),
		activation=activation,
		use_bias=False,
		kernel_regularizer=None,
		bias_regularizer=None,
		activity_regularizer=None,
		kernel_constraint=None,
		bias_constraint=None,
		kq=kq,
		bq=bq,
		aq=aq,
		after_activation=after_activation)(x)
	x=keras.layers.normalization.BatchNormalization(name='conv_pw_2_bn',
		trainable=True,
		axis=-1,
		momentum=0.99,
		epsilon=0.001,
		center=True,
		scale=True,
		beta_initializer={'class_name': 'Zeros', 'config': {}},
		gamma_initializer={'class_name': 'Ones', 'config': {}},
		moving_mean_initializer={'class_name': 'Zeros', 'config': {}},
		moving_variance_initializer={'class_name': 'Ones', 'config': {}},
		beta_regularizer=None,
		gamma_regularizer=None,
		beta_constraint=None,
		gamma_constraint=None)(x)
	x=keras.layers.advanced_activations.ReLU(name='conv_pw_2_relu',
		trainable=True,
		max_value=6.0,
		negative_slope=0.0,
		threshold=0.0)(x)
	x=DepthwiseConv2D_Q(name='conv_dw_3',
		trainable=True,
		kernel_size=(3, 3),
		strides=(1, 1),
		padding='same',
		data_format='channels_last',
		dilation_rate=(1, 1),
		activation=activation,
		use_bias=False,
		bias_regularizer=None,
		activity_regularizer=None,
		bias_constraint=None,
		depth_multiplier=1,
		depthwise_initializer={'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}},
		depthwise_regularizer=None,
		depthwise_constraint=None,
		kq=kq,
		bq=bq,
		aq=aq,
		after_activation=after_activation)(x)
	x=keras.layers.normalization.BatchNormalization(name='conv_dw_3_bn',
		trainable=True,
		axis=-1,
		momentum=0.99,
		epsilon=0.001,
		center=True,
		scale=True,
		beta_initializer={'class_name': 'Zeros', 'config': {}},
		gamma_initializer={'class_name': 'Ones', 'config': {}},
		moving_mean_initializer={'class_name': 'Zeros', 'config': {}},
		moving_variance_initializer={'class_name': 'Ones', 'config': {}},
		beta_regularizer=None,
		gamma_regularizer=None,
		beta_constraint=None,
		gamma_constraint=None)(x)
	x=keras.layers.advanced_activations.ReLU(name='conv_dw_3_relu',
		trainable=True,
		max_value=6.0,
		negative_slope=0.0,
		threshold=0.0)(x)
	x=Conv2D_Q(name='conv_pw_3',
		trainable=True,
		filters=128,
		kernel_size=(1, 1),
		strides=(1, 1),
		padding='same',
		data_format='channels_last',
		dilation_rate=(1, 1),
		activation=activation,
		use_bias=False,
		kernel_regularizer=None,
		bias_regularizer=None,
		activity_regularizer=None,
		kernel_constraint=None,
		bias_constraint=None,
		kq=kq,
		bq=bq,
		aq=aq,
		after_activation=after_activation)(x)
	x=keras.layers.normalization.BatchNormalization(name='conv_pw_3_bn',
		trainable=True,
		axis=-1,
		momentum=0.99,
		epsilon=0.001,
		center=True,
		scale=True,
		beta_initializer={'class_name': 'Zeros', 'config': {}},
		gamma_initializer={'class_name': 'Ones', 'config': {}},
		moving_mean_initializer={'class_name': 'Zeros', 'config': {}},
		moving_variance_initializer={'class_name': 'Ones', 'config': {}},
		beta_regularizer=None,
		gamma_regularizer=None,
		beta_constraint=None,
		gamma_constraint=None)(x)
	x=keras.layers.advanced_activations.ReLU(name='conv_pw_3_relu',
		trainable=True,
		max_value=6.0,
		negative_slope=0.0,
		threshold=0.0)(x)
	x=keras.layers.convolutional.ZeroPadding2D(name='conv_pad_4',
		trainable=True,
		padding=((0, 1), (0, 1)),
		data_format='channels_last')(x)
	x=DepthwiseConv2D_Q(name='conv_dw_4',
		trainable=True,
		kernel_size=(3, 3),
		strides=(2, 2),
		padding='valid',
		data_format='channels_last',
		dilation_rate=(1, 1),
		activation=activation,
		use_bias=False,
		bias_regularizer=None,
		activity_regularizer=None,
		bias_constraint=None,
		depth_multiplier=1,
		depthwise_initializer={'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}},
		depthwise_regularizer=None,
		depthwise_constraint=None,
		kq=kq,
		bq=bq,
		aq=aq,
		after_activation=after_activation)(x)
	x=keras.layers.normalization.BatchNormalization(name='conv_dw_4_bn',
		trainable=True,
		axis=-1,
		momentum=0.99,
		epsilon=0.001,
		center=True,
		scale=True,
		beta_initializer={'class_name': 'Zeros', 'config': {}},
		gamma_initializer={'class_name': 'Ones', 'config': {}},
		moving_mean_initializer={'class_name': 'Zeros', 'config': {}},
		moving_variance_initializer={'class_name': 'Ones', 'config': {}},
		beta_regularizer=None,
		gamma_regularizer=None,
		beta_constraint=None,
		gamma_constraint=None)(x)
	x=keras.layers.advanced_activations.ReLU(name='conv_dw_4_relu',
		trainable=True,
		max_value=6.0,
		negative_slope=0.0,
		threshold=0.0)(x)
	x=Conv2D_Q(name='conv_pw_4',
		trainable=True,
		filters=256,
		kernel_size=(1, 1),
		strides=(1, 1),
		padding='same',
		data_format='channels_last',
		dilation_rate=(1, 1),
		activation=activation,
		use_bias=False,
		kernel_regularizer=None,
		bias_regularizer=None,
		activity_regularizer=None,
		kernel_constraint=None,
		bias_constraint=None,
		kq=kq,
		bq=bq,
		aq=aq,
		after_activation=after_activation)(x)
	x=keras.layers.normalization.BatchNormalization(name='conv_pw_4_bn',
		trainable=True,
		axis=-1,
		momentum=0.99,
		epsilon=0.001,
		center=True,
		scale=True,
		beta_initializer={'class_name': 'Zeros', 'config': {}},
		gamma_initializer={'class_name': 'Ones', 'config': {}},
		moving_mean_initializer={'class_name': 'Zeros', 'config': {}},
		moving_variance_initializer={'class_name': 'Ones', 'config': {}},
		beta_regularizer=None,
		gamma_regularizer=None,
		beta_constraint=None,
		gamma_constraint=None)(x)
	x=keras.layers.advanced_activations.ReLU(name='conv_pw_4_relu',
		trainable=True,
		max_value=6.0,
		negative_slope=0.0,
		threshold=0.0)(x)
	x=DepthwiseConv2D_Q(name='conv_dw_5',
		trainable=True,
		kernel_size=(3, 3),
		strides=(1, 1),
		padding='same',
		data_format='channels_last',
		dilation_rate=(1, 1),
		activation=activation,
		use_bias=False,
		bias_regularizer=None,
		activity_regularizer=None,
		bias_constraint=None,
		depth_multiplier=1,
		depthwise_initializer={'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}},
		depthwise_regularizer=None,
		depthwise_constraint=None,
		kq=kq,
		bq=bq,
		aq=aq,
		after_activation=after_activation)(x)
	x=keras.layers.normalization.BatchNormalization(name='conv_dw_5_bn',
		trainable=True,
		axis=-1,
		momentum=0.99,
		epsilon=0.001,
		center=True,
		scale=True,
		beta_initializer={'class_name': 'Zeros', 'config': {}},
		gamma_initializer={'class_name': 'Ones', 'config': {}},
		moving_mean_initializer={'class_name': 'Zeros', 'config': {}},
		moving_variance_initializer={'class_name': 'Ones', 'config': {}},
		beta_regularizer=None,
		gamma_regularizer=None,
		beta_constraint=None,
		gamma_constraint=None)(x)
	x=keras.layers.advanced_activations.ReLU(name='conv_dw_5_relu',
		trainable=True,
		max_value=6.0,
		negative_slope=0.0,
		threshold=0.0)(x)
	x=Conv2D_Q(name='conv_pw_5',
		trainable=True,
		filters=256,
		kernel_size=(1, 1),
		strides=(1, 1),
		padding='same',
		data_format='channels_last',
		dilation_rate=(1, 1),
		activation=activation,
		use_bias=False,
		kernel_regularizer=None,
		bias_regularizer=None,
		activity_regularizer=None,
		kernel_constraint=None,
		bias_constraint=None,
		kq=kq,
		bq=bq,
		aq=aq,
		after_activation=after_activation)(x)
	x=keras.layers.normalization.BatchNormalization(name='conv_pw_5_bn',
		trainable=True,
		axis=-1,
		momentum=0.99,
		epsilon=0.001,
		center=True,
		scale=True,
		beta_initializer={'class_name': 'Zeros', 'config': {}},
		gamma_initializer={'class_name': 'Ones', 'config': {}},
		moving_mean_initializer={'class_name': 'Zeros', 'config': {}},
		moving_variance_initializer={'class_name': 'Ones', 'config': {}},
		beta_regularizer=None,
		gamma_regularizer=None,
		beta_constraint=None,
		gamma_constraint=None)(x)
	x=keras.layers.advanced_activations.ReLU(name='conv_pw_5_relu',
		trainable=True,
		max_value=6.0,
		negative_slope=0.0,
		threshold=0.0)(x)
	x=keras.layers.convolutional.ZeroPadding2D(name='conv_pad_6',
		trainable=True,
		padding=((0, 1), (0, 1)),
		data_format='channels_last')(x)
	x=DepthwiseConv2D_Q(name='conv_dw_6',
		trainable=True,
		kernel_size=(3, 3),
		strides=(2, 2),
		padding='valid',
		data_format='channels_last',
		dilation_rate=(1, 1),
		activation=activation,
		use_bias=False,
		bias_regularizer=None,
		activity_regularizer=None,
		bias_constraint=None,
		depth_multiplier=1,
		depthwise_initializer={'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}},
		depthwise_regularizer=None,
		depthwise_constraint=None,
		kq=kq,
		bq=bq,
		aq=aq,
		after_activation=after_activation)(x)
	x=keras.layers.normalization.BatchNormalization(name='conv_dw_6_bn',
		trainable=True,
		axis=-1,
		momentum=0.99,
		epsilon=0.001,
		center=True,
		scale=True,
		beta_initializer={'class_name': 'Zeros', 'config': {}},
		gamma_initializer={'class_name': 'Ones', 'config': {}},
		moving_mean_initializer={'class_name': 'Zeros', 'config': {}},
		moving_variance_initializer={'class_name': 'Ones', 'config': {}},
		beta_regularizer=None,
		gamma_regularizer=None,
		beta_constraint=None,
		gamma_constraint=None)(x)
	x=keras.layers.advanced_activations.ReLU(name='conv_dw_6_relu',
		trainable=True,
		max_value=6.0,
		negative_slope=0.0,
		threshold=0.0)(x)
	x=Conv2D_Q(name='conv_pw_6',
		trainable=True,
		filters=512,
		kernel_size=(1, 1),
		strides=(1, 1),
		padding='same',
		data_format='channels_last',
		dilation_rate=(1, 1),
		activation=activation,
		use_bias=False,
		kernel_regularizer=None,
		bias_regularizer=None,
		activity_regularizer=None,
		kernel_constraint=None,
		bias_constraint=None,
		kq=kq,
		bq=bq,
		aq=aq,
		after_activation=after_activation)(x)
	x=keras.layers.normalization.BatchNormalization(name='conv_pw_6_bn',
		trainable=True,
		axis=-1,
		momentum=0.99,
		epsilon=0.001,
		center=True,
		scale=True,
		beta_initializer={'class_name': 'Zeros', 'config': {}},
		gamma_initializer={'class_name': 'Ones', 'config': {}},
		moving_mean_initializer={'class_name': 'Zeros', 'config': {}},
		moving_variance_initializer={'class_name': 'Ones', 'config': {}},
		beta_regularizer=None,
		gamma_regularizer=None,
		beta_constraint=None,
		gamma_constraint=None)(x)
	x=keras.layers.advanced_activations.ReLU(name='conv_pw_6_relu',
		trainable=True,
		max_value=6.0,
		negative_slope=0.0,
		threshold=0.0)(x)
	x=DepthwiseConv2D_Q(name='conv_dw_7',
		trainable=True,
		kernel_size=(3, 3),
		strides=(1, 1),
		padding='same',
		data_format='channels_last',
		dilation_rate=(1, 1),
		activation=activation,
		use_bias=False,
		bias_regularizer=None,
		activity_regularizer=None,
		bias_constraint=None,
		depth_multiplier=1,
		depthwise_initializer={'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}},
		depthwise_regularizer=None,
		depthwise_constraint=None,
		kq=kq,
		bq=bq,
		aq=aq,
		after_activation=after_activation)(x)
	x=keras.layers.normalization.BatchNormalization(name='conv_dw_7_bn',
		trainable=True,
		axis=-1,
		momentum=0.99,
		epsilon=0.001,
		center=True,
		scale=True,
		beta_initializer={'class_name': 'Zeros', 'config': {}},
		gamma_initializer={'class_name': 'Ones', 'config': {}},
		moving_mean_initializer={'class_name': 'Zeros', 'config': {}},
		moving_variance_initializer={'class_name': 'Ones', 'config': {}},
		beta_regularizer=None,
		gamma_regularizer=None,
		beta_constraint=None,
		gamma_constraint=None)(x)
	x=keras.layers.advanced_activations.ReLU(name='conv_dw_7_relu',
		trainable=True,
		max_value=6.0,
		negative_slope=0.0,
		threshold=0.0)(x)
	x=Conv2D_Q(name='conv_pw_7',
		trainable=True,
		filters=512,
		kernel_size=(1, 1),
		strides=(1, 1),
		padding='same',
		data_format='channels_last',
		dilation_rate=(1, 1),
		activation=activation,
		use_bias=False,
		kernel_regularizer=None,
		bias_regularizer=None,
		activity_regularizer=None,
		kernel_constraint=None,
		bias_constraint=None,
		kq=kq,
		bq=bq,
		aq=aq,
		after_activation=after_activation)(x)
	x=keras.layers.normalization.BatchNormalization(name='conv_pw_7_bn',
		trainable=True,
		axis=-1,
		momentum=0.99,
		epsilon=0.001,
		center=True,
		scale=True,
		beta_initializer={'class_name': 'Zeros', 'config': {}},
		gamma_initializer={'class_name': 'Ones', 'config': {}},
		moving_mean_initializer={'class_name': 'Zeros', 'config': {}},
		moving_variance_initializer={'class_name': 'Ones', 'config': {}},
		beta_regularizer=None,
		gamma_regularizer=None,
		beta_constraint=None,
		gamma_constraint=None)(x)
	x=keras.layers.advanced_activations.ReLU(name='conv_pw_7_relu',
		trainable=True,
		max_value=6.0,
		negative_slope=0.0,
		threshold=0.0)(x)
	x=DepthwiseConv2D_Q(name='conv_dw_8',
		trainable=True,
		kernel_size=(3, 3),
		strides=(1, 1),
		padding='same',
		data_format='channels_last',
		dilation_rate=(1, 1),
		activation=activation,
		use_bias=False,
		bias_regularizer=None,
		activity_regularizer=None,
		bias_constraint=None,
		depth_multiplier=1,
		depthwise_initializer={'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}},
		depthwise_regularizer=None,
		depthwise_constraint=None,
		kq=kq,
		bq=bq,
		aq=aq,
		after_activation=after_activation)(x)
	x=keras.layers.normalization.BatchNormalization(name='conv_dw_8_bn',
		trainable=True,
		axis=-1,
		momentum=0.99,
		epsilon=0.001,
		center=True,
		scale=True,
		beta_initializer={'class_name': 'Zeros', 'config': {}},
		gamma_initializer={'class_name': 'Ones', 'config': {}},
		moving_mean_initializer={'class_name': 'Zeros', 'config': {}},
		moving_variance_initializer={'class_name': 'Ones', 'config': {}},
		beta_regularizer=None,
		gamma_regularizer=None,
		beta_constraint=None,
		gamma_constraint=None)(x)
	x=keras.layers.advanced_activations.ReLU(name='conv_dw_8_relu',
		trainable=True,
		max_value=6.0,
		negative_slope=0.0,
		threshold=0.0)(x)
	x=Conv2D_Q(name='conv_pw_8',
		trainable=True,
		filters=512,
		kernel_size=(1, 1),
		strides=(1, 1),
		padding='same',
		data_format='channels_last',
		dilation_rate=(1, 1),
		activation=activation,
		use_bias=False,
		kernel_regularizer=None,
		bias_regularizer=None,
		activity_regularizer=None,
		kernel_constraint=None,
		bias_constraint=None,
		kq=kq,
		bq=bq,
		aq=aq,
		after_activation=after_activation)(x)
	x=keras.layers.normalization.BatchNormalization(name='conv_pw_8_bn',
		trainable=True,
		axis=-1,
		momentum=0.99,
		epsilon=0.001,
		center=True,
		scale=True,
		beta_initializer={'class_name': 'Zeros', 'config': {}},
		gamma_initializer={'class_name': 'Ones', 'config': {}},
		moving_mean_initializer={'class_name': 'Zeros', 'config': {}},
		moving_variance_initializer={'class_name': 'Ones', 'config': {}},
		beta_regularizer=None,
		gamma_regularizer=None,
		beta_constraint=None,
		gamma_constraint=None)(x)
	x=keras.layers.advanced_activations.ReLU(name='conv_pw_8_relu',
		trainable=True,
		max_value=6.0,
		negative_slope=0.0,
		threshold=0.0)(x)
	x=DepthwiseConv2D_Q(name='conv_dw_9',
		trainable=True,
		kernel_size=(3, 3),
		strides=(1, 1),
		padding='same',
		data_format='channels_last',
		dilation_rate=(1, 1),
		activation=activation,
		use_bias=False,
		bias_regularizer=None,
		activity_regularizer=None,
		bias_constraint=None,
		depth_multiplier=1,
		depthwise_initializer={'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}},
		depthwise_regularizer=None,
		depthwise_constraint=None,
		kq=kq,
		bq=bq,
		aq=aq,
		after_activation=after_activation)(x)
	x=keras.layers.normalization.BatchNormalization(name='conv_dw_9_bn',
		trainable=True,
		axis=-1,
		momentum=0.99,
		epsilon=0.001,
		center=True,
		scale=True,
		beta_initializer={'class_name': 'Zeros', 'config': {}},
		gamma_initializer={'class_name': 'Ones', 'config': {}},
		moving_mean_initializer={'class_name': 'Zeros', 'config': {}},
		moving_variance_initializer={'class_name': 'Ones', 'config': {}},
		beta_regularizer=None,
		gamma_regularizer=None,
		beta_constraint=None,
		gamma_constraint=None)(x)
	x=keras.layers.advanced_activations.ReLU(name='conv_dw_9_relu',
		trainable=True,
		max_value=6.0,
		negative_slope=0.0,
		threshold=0.0)(x)
	x=Conv2D_Q(name='conv_pw_9',
		trainable=True,
		filters=512,
		kernel_size=(1, 1),
		strides=(1, 1),
		padding='same',
		data_format='channels_last',
		dilation_rate=(1, 1),
		activation=activation,
		use_bias=False,
		kernel_regularizer=None,
		bias_regularizer=None,
		activity_regularizer=None,
		kernel_constraint=None,
		bias_constraint=None,
		kq=kq,
		bq=bq,
		aq=aq,
		after_activation=after_activation)(x)
	x=keras.layers.normalization.BatchNormalization(name='conv_pw_9_bn',
		trainable=True,
		axis=-1,
		momentum=0.99,
		epsilon=0.001,
		center=True,
		scale=True,
		beta_initializer={'class_name': 'Zeros', 'config': {}},
		gamma_initializer={'class_name': 'Ones', 'config': {}},
		moving_mean_initializer={'class_name': 'Zeros', 'config': {}},
		moving_variance_initializer={'class_name': 'Ones', 'config': {}},
		beta_regularizer=None,
		gamma_regularizer=None,
		beta_constraint=None,
		gamma_constraint=None)(x)
	x=keras.layers.advanced_activations.ReLU(name='conv_pw_9_relu',
		trainable=True,
		max_value=6.0,
		negative_slope=0.0,
		threshold=0.0)(x)
	x=DepthwiseConv2D_Q(name='conv_dw_10',
		trainable=True,
		kernel_size=(3, 3),
		strides=(1, 1),
		padding='same',
		data_format='channels_last',
		dilation_rate=(1, 1),
		activation=activation,
		use_bias=False,
		bias_regularizer=None,
		activity_regularizer=None,
		bias_constraint=None,
		depth_multiplier=1,
		depthwise_initializer={'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}},
		depthwise_regularizer=None,
		depthwise_constraint=None,
		kq=kq,
		bq=bq,
		aq=aq,
		after_activation=after_activation)(x)
	x=keras.layers.normalization.BatchNormalization(name='conv_dw_10_bn',
		trainable=True,
		axis=-1,
		momentum=0.99,
		epsilon=0.001,
		center=True,
		scale=True,
		beta_initializer={'class_name': 'Zeros', 'config': {}},
		gamma_initializer={'class_name': 'Ones', 'config': {}},
		moving_mean_initializer={'class_name': 'Zeros', 'config': {}},
		moving_variance_initializer={'class_name': 'Ones', 'config': {}},
		beta_regularizer=None,
		gamma_regularizer=None,
		beta_constraint=None,
		gamma_constraint=None)(x)
	x=keras.layers.advanced_activations.ReLU(name='conv_dw_10_relu',
		trainable=True,
		max_value=6.0,
		negative_slope=0.0,
		threshold=0.0)(x)
	x=Conv2D_Q(name='conv_pw_10',
		trainable=True,
		filters=512,
		kernel_size=(1, 1),
		strides=(1, 1),
		padding='same',
		data_format='channels_last',
		dilation_rate=(1, 1),
		activation=activation,
		use_bias=False,
		kernel_regularizer=None,
		bias_regularizer=None,
		activity_regularizer=None,
		kernel_constraint=None,
		bias_constraint=None,
		kq=kq,
		bq=bq,
		aq=aq,
		after_activation=after_activation)(x)
	x=keras.layers.normalization.BatchNormalization(name='conv_pw_10_bn',
		trainable=True,
		axis=-1,
		momentum=0.99,
		epsilon=0.001,
		center=True,
		scale=True,
		beta_initializer={'class_name': 'Zeros', 'config': {}},
		gamma_initializer={'class_name': 'Ones', 'config': {}},
		moving_mean_initializer={'class_name': 'Zeros', 'config': {}},
		moving_variance_initializer={'class_name': 'Ones', 'config': {}},
		beta_regularizer=None,
		gamma_regularizer=None,
		beta_constraint=None,
		gamma_constraint=None)(x)
	x=keras.layers.advanced_activations.ReLU(name='conv_pw_10_relu',
		trainable=True,
		max_value=6.0,
		negative_slope=0.0,
		threshold=0.0)(x)
	x=DepthwiseConv2D_Q(name='conv_dw_11',
		trainable=True,
		kernel_size=(3, 3),
		strides=(1, 1),
		padding='same',
		data_format='channels_last',
		dilation_rate=(1, 1),
		activation=activation,
		use_bias=False,
		bias_regularizer=None,
		activity_regularizer=None,
		bias_constraint=None,
		depth_multiplier=1,
		depthwise_initializer={'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}},
		depthwise_regularizer=None,
		depthwise_constraint=None,
		kq=kq,
		bq=bq,
		aq=aq,
		after_activation=after_activation)(x)
	x=keras.layers.normalization.BatchNormalization(name='conv_dw_11_bn',
		trainable=True,
		axis=-1,
		momentum=0.99,
		epsilon=0.001,
		center=True,
		scale=True,
		beta_initializer={'class_name': 'Zeros', 'config': {}},
		gamma_initializer={'class_name': 'Ones', 'config': {}},
		moving_mean_initializer={'class_name': 'Zeros', 'config': {}},
		moving_variance_initializer={'class_name': 'Ones', 'config': {}},
		beta_regularizer=None,
		gamma_regularizer=None,
		beta_constraint=None,
		gamma_constraint=None)(x)
	x=keras.layers.advanced_activations.ReLU(name='conv_dw_11_relu',
		trainable=True,
		max_value=6.0,
		negative_slope=0.0,
		threshold=0.0)(x)
	x=Conv2D_Q(name='conv_pw_11',
		trainable=True,
		filters=512,
		kernel_size=(1, 1),
		strides=(1, 1),
		padding='same',
		data_format='channels_last',
		dilation_rate=(1, 1),
		activation=activation,
		use_bias=False,
		kernel_regularizer=None,
		bias_regularizer=None,
		activity_regularizer=None,
		kernel_constraint=None,
		bias_constraint=None,
		kq=kq,
		bq=bq,
		aq=aq,
		after_activation=after_activation)(x)
	x=keras.layers.normalization.BatchNormalization(name='conv_pw_11_bn',
		trainable=True,
		axis=-1,
		momentum=0.99,
		epsilon=0.001,
		center=True,
		scale=True,
		beta_initializer={'class_name': 'Zeros', 'config': {}},
		gamma_initializer={'class_name': 'Ones', 'config': {}},
		moving_mean_initializer={'class_name': 'Zeros', 'config': {}},
		moving_variance_initializer={'class_name': 'Ones', 'config': {}},
		beta_regularizer=None,
		gamma_regularizer=None,
		beta_constraint=None,
		gamma_constraint=None)(x)
	x=keras.layers.advanced_activations.ReLU(name='conv_pw_11_relu',
		trainable=True,
		max_value=6.0,
		negative_slope=0.0,
		threshold=0.0)(x)
	x=keras.layers.convolutional.ZeroPadding2D(name='conv_pad_12',
		trainable=True,
		padding=((0, 1), (0, 1)),
		data_format='channels_last')(x)
	x=DepthwiseConv2D_Q(name='conv_dw_12',
		trainable=True,
		kernel_size=(3, 3),
		strides=(2, 2),
		padding='valid',
		data_format='channels_last',
		dilation_rate=(1, 1),
		activation=activation,
		use_bias=False,
		bias_regularizer=None,
		activity_regularizer=None,
		bias_constraint=None,
		depth_multiplier=1,
		depthwise_initializer={'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}},
		depthwise_regularizer=None,
		depthwise_constraint=None,
		kq=kq,
		bq=bq,
		aq=aq,
		after_activation=after_activation)(x)
	x=keras.layers.normalization.BatchNormalization(name='conv_dw_12_bn',
		trainable=True,
		axis=-1,
		momentum=0.99,
		epsilon=0.001,
		center=True,
		scale=True,
		beta_initializer={'class_name': 'Zeros', 'config': {}},
		gamma_initializer={'class_name': 'Ones', 'config': {}},
		moving_mean_initializer={'class_name': 'Zeros', 'config': {}},
		moving_variance_initializer={'class_name': 'Ones', 'config': {}},
		beta_regularizer=None,
		gamma_regularizer=None,
		beta_constraint=None,
		gamma_constraint=None)(x)
	x=keras.layers.advanced_activations.ReLU(name='conv_dw_12_relu',
		trainable=True,
		max_value=6.0,
		negative_slope=0.0,
		threshold=0.0)(x)
	x=Conv2D_Q(name='conv_pw_12',
		trainable=True,
		filters=1024,
		kernel_size=(1, 1),
		strides=(1, 1),
		padding='same',
		data_format='channels_last',
		dilation_rate=(1, 1),
		activation=activation,
		use_bias=False,
		kernel_regularizer=None,
		bias_regularizer=None,
		activity_regularizer=None,
		kernel_constraint=None,
		bias_constraint=None,
		kq=kq,
		bq=bq,
		aq=aq,
		after_activation=after_activation)(x)
	x=keras.layers.normalization.BatchNormalization(name='conv_pw_12_bn',
		trainable=True,
		axis=-1,
		momentum=0.99,
		epsilon=0.001,
		center=True,
		scale=True,
		beta_initializer={'class_name': 'Zeros', 'config': {}},
		gamma_initializer={'class_name': 'Ones', 'config': {}},
		moving_mean_initializer={'class_name': 'Zeros', 'config': {}},
		moving_variance_initializer={'class_name': 'Ones', 'config': {}},
		beta_regularizer=None,
		gamma_regularizer=None,
		beta_constraint=None,
		gamma_constraint=None)(x)
	x=keras.layers.advanced_activations.ReLU(name='conv_pw_12_relu',
		trainable=True,
		max_value=6.0,
		negative_slope=0.0,
		threshold=0.0)(x)
	x=DepthwiseConv2D_Q(name='conv_dw_13',
		trainable=True,
		kernel_size=(3, 3),
		strides=(1, 1),
		padding='same',
		data_format='channels_last',
		dilation_rate=(1, 1),
		activation=activation,
		use_bias=False,
		bias_regularizer=None,
		activity_regularizer=None,
		bias_constraint=None,
		depth_multiplier=1,
		depthwise_initializer={'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}},
		depthwise_regularizer=None,
		depthwise_constraint=None,
		kq=kq,
		bq=bq,
		aq=aq,
		after_activation=after_activation)(x)
	x=keras.layers.normalization.BatchNormalization(name='conv_dw_13_bn',
		trainable=True,
		axis=-1,
		momentum=0.99,
		epsilon=0.001,
		center=True,
		scale=True,
		beta_initializer={'class_name': 'Zeros', 'config': {}},
		gamma_initializer={'class_name': 'Ones', 'config': {}},
		moving_mean_initializer={'class_name': 'Zeros', 'config': {}},
		moving_variance_initializer={'class_name': 'Ones', 'config': {}},
		beta_regularizer=None,
		gamma_regularizer=None,
		beta_constraint=None,
		gamma_constraint=None)(x)
	x=keras.layers.advanced_activations.ReLU(name='conv_dw_13_relu',
		trainable=True,
		max_value=6.0,
		negative_slope=0.0,
		threshold=0.0)(x)
	x=Conv2D_Q(name='conv_pw_13',
		trainable=True,
		filters=1024,
		kernel_size=(1, 1),
		strides=(1, 1),
		padding='same',
		data_format='channels_last',
		dilation_rate=(1, 1),
		activation=activation,
		use_bias=False,
		kernel_regularizer=None,
		bias_regularizer=None,
		activity_regularizer=None,
		kernel_constraint=None,
		bias_constraint=None,
		kq=kq,
		bq=bq,
		aq=aq,
		after_activation=after_activation)(x)
	x=keras.layers.normalization.BatchNormalization(name='conv_pw_13_bn',
		trainable=True,
		axis=-1,
		momentum=0.99,
		epsilon=0.001,
		center=True,
		scale=True,
		beta_initializer={'class_name': 'Zeros', 'config': {}},
		gamma_initializer={'class_name': 'Ones', 'config': {}},
		moving_mean_initializer={'class_name': 'Zeros', 'config': {}},
		moving_variance_initializer={'class_name': 'Ones', 'config': {}},
		beta_regularizer=None,
		gamma_regularizer=None,
		beta_constraint=None,
		gamma_constraint=None)(x)
	x=keras.layers.advanced_activations.ReLU(name='conv_pw_13_relu',
		trainable=True,
		max_value=6.0,
		negative_slope=0.0,
		threshold=0.0)(x)
	x=keras.layers.pooling.GlobalAveragePooling2D(name='global_average_pooling2d_1',
		trainable=True,
		data_format='channels_last')(x)
	x=keras.layers.core.Reshape(name='reshape_1',
		trainable=True,
		target_shape=(1, 1, 1024))(x)
	x=keras.layers.core.Dropout(name='dropout',
		trainable=True,
		rate=0.001,
		noise_shape=None,
		seed=None)(x)
	x=Conv2D_Q(name='conv_preds',
		trainable=True,
		filters=1000,
		kernel_size=(1, 1),
		strides=(1, 1),
		padding='same',
		data_format='channels_last',
		dilation_rate=(1, 1),
		activation=None,
		use_bias=True,
		kernel_regularizer=None,
		bias_regularizer=None,
		activity_regularizer=None,
		kernel_constraint=None,
		bias_constraint=None,
		kq=kq,
		bq=bq)(x)
	x=keras.layers.core.Reshape(name='reshape_2',
		trainable=True,
		target_shape=(1000,))(x)
	outputs=keras.layers.core.Activation(name='act_softmax',
		trainable=True,
		activation='softmax')(x)
	model=keras.models.Model(inputs,outputs)
	return model
